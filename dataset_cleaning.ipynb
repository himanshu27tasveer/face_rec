{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dataset_cleaning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCT4CAbQRFW95aW4mEgVKt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshu27tasveer/face_rec/blob/main/dataset_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrpJZkKO5-sO"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "id": "zgDk0TwY6IY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os,cv2,time\n",
        "import MTCNN\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def MTCNN_alignment(root_dir,output_dir,detect_multiple_faces=False,output_size=None,margin=44,dataset_range=None,\n",
        "                    GPU_ratio=None,img_show=False):\n",
        "    # ----record the start time\n",
        "    d_t = time.time()\n",
        "\n",
        "    #----var\n",
        "    img_format = {'png', 'bmp', 'jpg'}\n",
        "    quantity = 0\n",
        "\n",
        "    #----collect all folders\n",
        "    dirs = [obj.path for obj in os.scandir(root_dir) if obj.is_dir()]\n",
        "    if len(dirs) == 0:\n",
        "        print(\"No sub folders in \", root_dir)\n",
        "    else:\n",
        "        dirs.sort()\n",
        "        print(\"Total class number: \", len(dirs))\n",
        "        if dataset_range is not None:\n",
        "            dirs = dirs[dataset_range[0]:dataset_range[1]]\n",
        "            print(\"Working classes: {} to {}\".format(dataset_range[0], dataset_range[1]))\n",
        "        else:\n",
        "            print(\"Working classes:All\")\n",
        "\n",
        "        #----initialization of MTCNN model\n",
        "        minsize = 20  # minimum size of face\n",
        "        threshold = [0.6, 0.7, 0.7]  # three steps's threshold\n",
        "        factor = 0.709  # scale factor\n",
        "        with tf.Graph().as_default():\n",
        "            config = tf.ConfigProto(log_device_placement=True,\n",
        "                                    allow_soft_placement=True,\n",
        "                                    )\n",
        "            if GPU_ratio is None:\n",
        "                config.gpu_options.allow_growth = True\n",
        "            else:\n",
        "                config.gpu_options.per_process_gpu_memory_fraction = GPU_ratio\n",
        "            sess = tf.Session(config=config)\n",
        "            with sess.as_default():\n",
        "                pnet, rnet, onet = MTCNN.create_mtcnn(sess, None)\n",
        "\n",
        "        #----handle images of each dir\n",
        "        for dir_path in dirs:\n",
        "                paths = [file.path for file in os.scandir(dir_path) if file.name.split(\".\")[-1] in img_format]\n",
        "                if len(paths) == 0:\n",
        "                    print(\"No images in \", dir_path)\n",
        "                else:\n",
        "                    # ----create the save dir\n",
        "                    save_dir = os.path.join(output_dir, dir_path.split(\"\\\\\")[-1])\n",
        "                    if not os.path.exists(save_dir):\n",
        "                        os.makedirs(save_dir)\n",
        "\n",
        "                    #----read images\n",
        "                    quantity += len(paths)\n",
        "                    for idx, path in enumerate(paths):\n",
        "                        img = cv2.imread(path)\n",
        "                        if img is None:\n",
        "                            print(\"Read failed:\", path)\n",
        "                        else:\n",
        "                            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)#img[:,:,::-1]\n",
        "                            bounding_boxes, _ = MTCNN.detect_face(img_rgb, minsize, pnet, rnet, onet,\n",
        "                                                                             threshold, factor)\n",
        "\n",
        "                            # ----bounding boxes processing\n",
        "                            nrof_faces = bounding_boxes.shape[0]\n",
        "                            if nrof_faces > 0:\n",
        "                                det = bounding_boxes[:, 0:4]\n",
        "                                det_arr = []\n",
        "                                img_size = np.asarray(img.shape)[0:2]\n",
        "                                if nrof_faces > 1:\n",
        "                                    if detect_multiple_faces:\n",
        "                                        for i in range(nrof_faces):\n",
        "                                            det_arr.append(np.squeeze(det[i]))\n",
        "                                    else:\n",
        "                                        bounding_box_size = (det[:, 2] - det[:, 0]) * (det[:, 3] - det[:, 1])\n",
        "                                        img_center = img_size / 2\n",
        "                                        offsets = np.vstack(\n",
        "                                            [(det[:, 0] + det[:, 2]) / 2 - img_center[1],\n",
        "                                             (det[:, 1] + det[:, 3]) / 2 - img_center[0]])\n",
        "                                        offset_dist_squared = np.sum(np.power(offsets, 2.0), 0)\n",
        "                                        index = np.argmax(\n",
        "                                            bounding_box_size - offset_dist_squared * 2.0)  # some extra weight on the centering\n",
        "                                        det_arr.append(det[index, :])\n",
        "                                else:\n",
        "                                    det_arr.append(np.squeeze(det))\n",
        "\n",
        "                                det_arr = np.array(det_arr)\n",
        "                                det_arr = det_arr.astype(np.int16)\n",
        "\n",
        "                                #----crop images\n",
        "                                for i, det in enumerate(det_arr):\n",
        "                                    det = np.squeeze(det)\n",
        "                                    bb = np.zeros(4, dtype=np.int32)\n",
        "                                    bb[0] = np.maximum(det[0] - margin / 2, 0)\n",
        "                                    bb[1] = np.maximum(det[1] - margin / 2, 0)\n",
        "                                    bb[2] = np.minimum(det[2] + margin / 2, img_size[1])\n",
        "                                    bb[3] = np.minimum(det[3] + margin / 2, img_size[0])\n",
        "                                    cropped = img[bb[1]:bb[3], bb[0]:bb[2], :]\n",
        "\n",
        "                                    # ----resize images\n",
        "                                    if output_size is not None:\n",
        "                                        cropped = cv2.resize(cropped,output_size)\n",
        "\n",
        "                                    #----save images\n",
        "                                    filename = path.split(\"/\")[-1]\n",
        "                                    if i == 0:\n",
        "                                        save_path = \"{}.{}\".format(filename.split(\".\")[0],'png')\n",
        "                                    else:\n",
        "                                        save_path = \"{}_{}.{}\".format(filename.split(\".\")[0], str(i),\n",
        "                                                                  'png')\n",
        "                                    save_path = os.path.join(save_dir, save_path)\n",
        "                                    cv2.imwrite(save_path, cropped)\n",
        "\n",
        "                                    #----display images\n",
        "                                    if img_show is True:\n",
        "                                        plt.subplot(1, 2, 1)\n",
        "                                        plt.imshow(img[:, :, ::-1])\n",
        "                                        plt.axis(\"off\")\n",
        "\n",
        "                                        plt.subplot(1, 2, 2)\n",
        "                                        plt.imshow(cropped[:, :, ::-1])\n",
        "                                        plt.axis(\"off\")\n",
        "\n",
        "                                        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #----statistics(to know the average process time of each image)\n",
        "    if quantity != 0:\n",
        "        d_t = time.time() - d_t\n",
        "        print(\"ave process time of each image:\", d_t / quantity)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    root_dir = \"/content/CASIA-WebFace\"\n",
        "    output_dir = \"/content/CASIA-WebFace_Aligned\"\n",
        "    detect_multiple_faces = False\n",
        "    output_size = None\n",
        "    margin = 44\n",
        "    dataset_range = None\n",
        "    img_show = False\n",
        "    GPU_ratio = None\n",
        "\n",
        "    MTCNN_alignment(root_dir, output_dir, detect_multiple_faces=detect_multiple_faces, output_size=output_size,\n",
        "                    margin=margin, dataset_range=dataset_range, GPU_ratio=GPU_ratio, img_show=img_show)"
      ],
      "metadata": {
        "id": "2-QZwXfh6NrQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}